{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import resample\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "from neurodsp.filt.filter import filter_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = gcsfs.GCSFileSystem(project='learning-2-learn-221016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'learning2learn/Buffalo/wcst-nhp/SA/sess-20180918/ephys/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = np.empty((124, 11796177))\n",
    "\n",
    "for chan in range(1, 125):\n",
    "    fname = op.join(path, f'chan-{chan}', f'sub-SA_sess-20180918_chan-{chan}.mat')\n",
    "    # print(f\"Opening {fname}\")\n",
    "    with fs.open(fname) as f_chan:\n",
    "        f_chan = loadmat(f_chan)\n",
    "        data[chan-1] = f_chan['data'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_signal(data, 1000, pass_type='highpass', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = resample(data, data.shape[-1]//10, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from picard import picard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixing(W, K):\n",
    "    w = np.dot(W, K)\n",
    "    return np.dot(w.T, np.linalg.inv(np.dot(w, w.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K, W, Y = picard(data, n_components=n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = mixing(W, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data[:, 200000:210000] + np.arange(0, data.shape[0] * 200, 200)[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = plt.plot((data[:20, 200000:200500] + np.arange(0, 20 * 5000, 5000)[:, None]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y[12, 200000:210000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 3\n",
    "mean_corr = [0]\n",
    "break_it = False\n",
    "\n",
    "while not break_it:   \n",
    "    K1, W1, Y1 = picard(data[:, :data.shape[-1]//2], n_components=n_components)\n",
    "    K2, W2, Y2 = picard(data[:, data.shape[-1]//2:], n_components=n_components)\n",
    "    mixing1 = mixing(W1, K1)\n",
    "    mixing2 = mixing(W2, K2)\n",
    "    \n",
    "    corr = np.empty((mixing1.shape[-1], mixing2.shape[-1]))\n",
    "    for ii in range(corr.shape[0]):\n",
    "        for jj in range(corr.shape[1]):\n",
    "            corr[ii, jj] = np.abs(np.corrcoef(mixing1[:, ii], mixing2[:, jj])[0, 1])\n",
    "    \n",
    "    new_mixing2 = np.empty_like(mixing2)\n",
    "    max_corr = np.zeros(mixing1.shape[-1])\n",
    "    for it in range(mixing1.shape[-1]):\n",
    "        max_corr[it] = np.nanmax(corr)\n",
    "        idx = np.where(corr == max_corr[it])\n",
    "        new_mixing2[:, idx[0]] = mixing2[:, idx[1]]\n",
    "        corr[idx[0], :] = np.nan\n",
    "        corr[:, idx[1]] = np.nan\n",
    "   \n",
    "    this_mean_corr = np.mean(max_corr)\n",
    "    if this_mean_corr < mean_corr[-1] and (mean_corr[-1] - this_mean_corr) > 0.05 * mean_corr[-1]:\n",
    "        mean_corr.append(this_mean_corr)\n",
    "        break_it = True\n",
    "    else:\n",
    "        mean_corr.append(this_mean_corr)\n",
    "    n_components = n_components + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mean_corr[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2)\n",
    "ax[0].matshow(new_mixing2[:10])\n",
    "ax[1].matshow(mixing1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another approach might be to rely on the fact that:\n",
    "# Y = WKX \n",
    "# To derive a cross-validated prediction of Y\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l2l",
   "language": "python",
   "name": "l2lhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
